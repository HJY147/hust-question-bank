"""
é…ç½®ç®¡ç†æ¨¡å—
ä»ç¯å¢ƒå˜é‡å’Œ.envæ–‡ä»¶åŠ è½½é…ç½®
"""
import os
from pathlib import Path
from typing import Optional

# é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = Path(__file__).parent.parent
BASE_DIR = str(PROJECT_ROOT)  # å…¼å®¹æ—§ä»£ç 

def load_env_file():
    """åŠ è½½.envæ–‡ä»¶åˆ°ç¯å¢ƒå˜é‡"""
    env_file = PROJECT_ROOT / '.env'
    if not env_file.exists():
        print(f"âš ï¸  æœªæ‰¾åˆ°.envæ–‡ä»¶ï¼Œå°†ä½¿ç”¨é»˜è®¤é…ç½®")
        print(f"ğŸ“ è¯·å¤åˆ¶ .env.template ä¸º .env å¹¶å¡«å…¥APIå¯†é’¥")
        return
    
    with open(env_file, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            # è·³è¿‡æ³¨é‡Šå’Œç©ºè¡Œ
            if not line or line.startswith('#'):
                continue
            # è§£æ KEY=VALUE
            if '=' in line:
                key, value = line.split('=', 1)
                key = key.strip()
                value = value.strip()
                # åªåœ¨ç¯å¢ƒå˜é‡æœªè®¾ç½®æ—¶æ‰è®¾ç½®
                if key and not os.getenv(key):
                    os.environ[key] = value

# è‡ªåŠ¨åŠ è½½.envæ–‡ä»¶
load_env_file()

# æ•°æ®ç›®å½•ï¼ˆå…¼å®¹æ—§ä»£ç ï¼‰
DATA_DIR = os.path.join(BASE_DIR, 'data')
QUESTION_BANK_DIR = os.path.join(DATA_DIR, 'question_bank')
ANSWERS_DIR = os.path.join(DATA_DIR, 'answers')
DATABASE_PATH = os.path.join(DATA_DIR, 'database.db')

# OCR é…ç½®
OCR_CONFIG = {
    'use_angle_cls': True,  # ä½¿ç”¨æ–¹å‘åˆ†ç±»å™¨
    'lang': 'ch',  # ä¸­æ–‡è¯†åˆ«
    'use_gpu': True,  # ä½¿ç”¨GPUåŠ é€Ÿï¼ˆå¦‚æœå¯ç”¨ï¼‰
    'det_db_thresh': 0.3,  # æ£€æµ‹é˜ˆå€¼
    'det_db_box_thresh': 0.5,  # æ–‡æœ¬æ¡†é˜ˆå€¼
}

# æ•°å­¦å…¬å¼è¯†åˆ«é…ç½®
MATH_OCR_CONFIG = {
    'enable': True,  # å¯ç”¨å…¬å¼è¯†åˆ«
    'model_name': 'pix2tex',  # å…¬å¼è¯†åˆ«æ¨¡å‹
}

# å›¾åƒé¢„å¤„ç†é…ç½®
IMAGE_PREPROCESS = {
    'resize': (800, 1200),  # è°ƒæ•´å¤§å°
    'denoise': True,  # å»å™ª
    'enhance_contrast': True,  # å¢å¼ºå¯¹æ¯”åº¦
    'binarize': False,  # äºŒå€¼åŒ–ï¼ˆå¯é€‰ï¼‰
}

# åŒ¹é…ç®—æ³•é…ç½®
MATCHING_CONFIG = {
    'similarity_threshold': 0.75,  # ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆ0-1ï¼‰
    'text_weight': 0.7,  # æ–‡æœ¬åŒ¹é…æƒé‡
    'image_weight': 0.3,  # å›¾åƒåŒ¹é…æƒé‡
    'top_k': 5,  # è¿”å›å‰Kä¸ªæœ€ç›¸ä¼¼ç»“æœ
}

# æ–‡æœ¬å‘é‡åŒ–æ¨¡å‹
TEXT_EMBEDDING_MODEL = 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'

# å›¾åƒç‰¹å¾æå–æ¨¡å‹
IMAGE_FEATURE_MODEL = 'resnet50'  # å¯é€‰ï¼šresnet50, vgg16, efficientnet

# ========== AIé…ç½®ç±» ==========
class Config:
    """AIå’ŒMLé…ç½®ç±»"""
    
    # ========== DeepSeeké…ç½® ==========
    DEEPSEEK_API_KEY: str = os.getenv('DEEPSEEK_API_KEY', '')
    DEEPSEEK_BASE_URL: str = os.getenv('DEEPSEEK_BASE_URL', 'https://api.deepseek.com/v1')
    
    # ========== è±†åŒ…é…ç½® ==========
    DOUBAO_API_KEY: str = os.getenv('DOUBAO_API_KEY', '')
    DOUBAO_ENDPOINT_ID: str = os.getenv('DOUBAO_ENDPOINT_ID', '')
    DOUBAO_REGION: str = os.getenv('DOUBAO_REGION', 'cn-beijing')
    
    # ========== AIåŠŸèƒ½å¼€å…³ ==========
    AI_FALLBACK_THRESHOLD: float = float(os.getenv('AI_FALLBACK_THRESHOLD', '0.6'))
    AI_TIMEOUT: int = int(os.getenv('AI_TIMEOUT', '15'))  # ä¼˜åŒ–ï¼šå‡å°‘è¶…æ—¶æ—¶é—´åˆ°15ç§’ï¼ŒåŠ å¿«å“åº”
    ENABLE_AI_SOLVER: bool = os.getenv('ENABLE_AI_SOLVER', 'true').lower() == 'true'
    ENABLE_IMAGE_OCR: bool = os.getenv('ENABLE_IMAGE_OCR', 'true').lower() == 'true'
    
    # ========== æ€§èƒ½ä¼˜åŒ–é…ç½® ==========
    MAX_TOKENS: int = int(os.getenv('MAX_TOKENS', '1200'))  # å‡å°‘tokenæ•°é‡åŠ å¿«ç”Ÿæˆ
    AI_TEMPERATURE: float = float(os.getenv('AI_TEMPERATURE', '0.1'))  # é™ä½éšæœºæ€§æé«˜é€Ÿåº¦
    STREAM_RESPONSE: bool = os.getenv('STREAM_RESPONSE', 'false').lower() == 'true'  # æµå¼å“åº”
    
    # ========== æœºå™¨å­¦ä¹ é…ç½® ==========
    ENABLE_ML_MATCHING: bool = os.getenv('ENABLE_ML_MATCHING', 'true').lower() == 'true'
    ML_MIN_SAMPLES: int = int(os.getenv('ML_MIN_SAMPLES', '10'))
    ML_TEXT_WEIGHT: float = float(os.getenv('ML_TEXT_WEIGHT', '0.6'))
    ML_IMAGE_WEIGHT: float = float(os.getenv('ML_IMAGE_WEIGHT', '0.4'))
    
    # ========== æ–‡ä»¶è·¯å¾„é…ç½® ==========
    DB_PATH: Path = PROJECT_ROOT / 'data' / 'questions.db'
    QUESTION_BANK_DIR_PATH: Path = PROJECT_ROOT / 'data' / 'question_bank'
    ANSWERS_DIR_PATH: Path = PROJECT_ROOT / 'data' / 'answers'
    UPLOAD_DIR: Path = PROJECT_ROOT / 'data' / 'uploads'
    ML_MODEL_DIR: Path = PROJECT_ROOT / 'data' / 'ml_models'
    
    @classmethod
    def validate(cls) -> tuple[bool, list[str]]:
        """
        éªŒè¯é…ç½®æ˜¯å¦å®Œæ•´
        
        Returns:
            (æ˜¯å¦æœ‰æ•ˆ, é”™è¯¯ä¿¡æ¯åˆ—è¡¨)
        """
        errors = []
        
        # æ£€æŸ¥DeepSeeké…ç½®
        if cls.ENABLE_AI_SOLVER:
            if not cls.DEEPSEEK_API_KEY or cls.DEEPSEEK_API_KEY == 'your_deepseek_api_key_here':
                errors.append("DeepSeek APIå¯†é’¥æœªé…ç½®")
        
        # æ£€æŸ¥è±†åŒ…é…ç½®
        if cls.ENABLE_IMAGE_OCR:
            if not cls.DOUBAO_API_KEY or cls.DOUBAO_API_KEY == 'your_doubao_api_key_here':
                errors.append("è±†åŒ… APIå¯†é’¥æœªé…ç½®")
            if not cls.DOUBAO_ENDPOINT_ID or cls.DOUBAO_ENDPOINT_ID == 'your_endpoint_id_here':
                errors.append("è±†åŒ… Endpoint IDæœªé…ç½®")
        
        # æ£€æŸ¥ç›®å½•
        for dir_path in [cls.QUESTION_BANK_DIR_PATH, cls.ANSWERS_DIR_PATH, cls.UPLOAD_DIR, cls.ML_MODEL_DIR]:
            dir_path.mkdir(parents=True, exist_ok=True)
        
        return len(errors) == 0, errors
    
    @classmethod
    def print_status(cls):
        """æ‰“å°é…ç½®çŠ¶æ€"""
        print("\n" + "="*60)
        print("ğŸ“‹ ç³»ç»Ÿé…ç½®çŠ¶æ€")
        print("="*60)
        
        # AIåŠŸèƒ½çŠ¶æ€
        print("\nğŸ¤– AIåŠŸèƒ½:")
        print(f"  DeepSeekè§£ç­”: {'âœ… å¯ç”¨' if cls.ENABLE_AI_SOLVER else 'âŒ ç¦ç”¨'}")
        if cls.ENABLE_AI_SOLVER:
            print(f"    APIå¯†é’¥: {'âœ… å·²é…ç½®' if cls.DEEPSEEK_API_KEY and cls.DEEPSEEK_API_KEY != 'your_deepseek_api_key_here' else 'âŒ æœªé…ç½®'}")
        
        print(f"  è±†åŒ…å›¾åƒè¯†åˆ«: {'âœ… å¯ç”¨' if cls.ENABLE_IMAGE_OCR else 'âŒ ç¦ç”¨'}")
        if cls.ENABLE_IMAGE_OCR:
            print(f"    APIå¯†é’¥: {'âœ… å·²é…ç½®' if cls.DOUBAO_API_KEY and cls.DOUBAO_API_KEY != 'your_doubao_api_key_here' else 'âŒ æœªé…ç½®'}")
        
        print(f"  AIè§¦å‘é˜ˆå€¼: {cls.AI_FALLBACK_THRESHOLD}")
        
        # æœºå™¨å­¦ä¹ çŠ¶æ€
        print(f"\nğŸ§  æœºå™¨å­¦ä¹ :")
        print(f"  å¢å¼ºåŒ¹é…: {'âœ… å¯ç”¨' if cls.ENABLE_ML_MATCHING else 'âŒ ç¦ç”¨'}")
        print(f"  æœ€å°æ ·æœ¬æ•°: {cls.ML_MIN_SAMPLES}")
        print(f"  æ–‡æœ¬æƒé‡: {cls.ML_TEXT_WEIGHT}")
        print(f"  å›¾åƒæƒé‡: {cls.ML_IMAGE_WEIGHT}")
        
        # éªŒè¯é…ç½®
        is_valid, errors = cls.validate()
        print(f"\nğŸ” é…ç½®éªŒè¯: {'âœ… é€šè¿‡' if is_valid else 'âŒ å¤±è´¥'}")
        if errors:
            print("  é”™è¯¯ä¿¡æ¯:")
            for error in errors:
                print(f"    â€¢ {error}")
        
        print("="*60 + "\n")

# åˆ›å»ºå…¨å±€é…ç½®å®ä¾‹
config = Config()

if __name__ == '__main__':
    # æµ‹è¯•é…ç½®
    config.print_status()

# CLIP æ¨¡å‹é…ç½® (ç”¨äºå›¾æ–‡è”åˆç†è§£)
CLIP_CONFIG = {
    'model_name': 'ViT-B-32',  # å¯é€‰: ViT-B-32, ViT-L-14, ViT-H-14
    'pretrained': 'laion2b_s34b_b79k',  # é¢„è®­ç»ƒæƒé‡
    'enable': True,  # æ˜¯å¦å¯ç”¨CLIP
}

# Ollama é…ç½® (æœ¬åœ°LLMå¢å¼º)
OLLAMA_CONFIG = {
    'base_url': 'http://localhost:11434',  # OllamaæœåŠ¡åœ°å€
    'model': 'qwen2:7b',  # æ¨èä½¿ç”¨çš„æ¨¡å‹: qwen2:7b, llama3:8b, mistral
    'timeout': 60,  # è¶…æ—¶æ—¶é—´(ç§’)
    'enable': True,  # æ˜¯å¦å¯ç”¨Ollamaå¢å¼º
}

# Flask é…ç½®
FLASK_CONFIG = {
    'host': '0.0.0.0',
    'port': 5000,
    'debug': True,
}

# ä¸Šä¼ æ–‡ä»¶é…ç½®
UPLOAD_CONFIG = {
    'max_file_size': 10 * 1024 * 1024,  # 10MB
    'allowed_extensions': {'png', 'jpg', 'jpeg', 'bmp', 'gif'},
    'upload_folder': os.path.join(DATA_DIR, 'uploads'),
}

# ç¡®ä¿ç›®å½•å­˜åœ¨
os.makedirs(QUESTION_BANK_DIR, exist_ok=True)
os.makedirs(ANSWERS_DIR, exist_ok=True)
os.makedirs(UPLOAD_CONFIG['upload_folder'], exist_ok=True)
